{
  "1": {
    "inputs": {
      "ckpt_name": "realisticVisionV51_v51VAE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "체크포인트 로드"
    }
  },
  "2": {
    "inputs": {
      "text": [
        "18",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP 텍스트 인코딩 (프롬프트)"
    }
  },
  "3": {
    "inputs": {
      "text": "blurry, low quality, low resolution, low contrast, deformed, disfigured, extra limbs, fused fingers, cropped, out of frame, bad anatomy, bad proportions, overexposed, underexposed, noisy, cartoon, anime, painting, illustration, text, watermark, logo, nsfw, grainy, unnatural skin, jpeg artifacts,\nhat, helmet, veil, accessory",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP 텍스트 인코딩 (프롬프트)"
    }
  },
  "13": {
    "inputs": {
      "model": "Florence-2-large-PromptGen-v2.0",
      "precision": "fp16",
      "attention": "sdpa",
      "convert_to_safetensors": false
    },
    "class_type": "Florence2ModelLoader",
    "_meta": {
      "title": "Florence2ModelLoader"
    }
  },
  "14": {
    "inputs": {
      "text_input": "",
      "task": "prompt_gen_tags",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 2048,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": [
        "153",
        0
      ],
      "seed": 1098112070142273,
      "image": [
        "287",
        0
      ],
      "florence2_model": [
        "13",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "15": {
    "inputs": {
      "delimiter": " ",
      "clean_whitespace": "true",
      "text_a": [
        "16",
        0
      ],
      "text_b": [
        "14",
        2
      ],
      "text_c": [
        "153",
        0
      ],
      "text_d": [
        "265",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "16": {
    "inputs": {
      "text": "(wearing"
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "17": {
    "inputs": {
      "text": "(full body:1.3), (standing, front-facing:1.3), (white background:1.3), solo, centered, symmetrical composition, fashion model, dynamic pose, studio lighting, pure white background, wide shot, high quality, ultra-detailed, 8k, DSLR, photo shoot, realistic, sharp focus, natural skin texture\n"
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "18": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "true",
      "text_a": [
        "172",
        0
      ],
      "text_b": [
        "15",
        0
      ],
      "text_c": [
        "17",
        0
      ],
      "text_d": [
        "19",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "19": {
    "inputs": {
      "text": "{prompt_text}"
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "139": {
    "inputs": {
      "image": "{image2}"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "이미지 로드"
    }
  },
  "153": {
    "inputs": {
      "value": "{clothes_type}"
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "문자열"
    }
  },
  "172": {
    "inputs": {
      "text": ""
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "198": {
    "inputs": {
      "samples": [
        "205",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE 디코드"
    }
  },
  "205": {
    "inputs": {
      "seed": [
        "219",
        0
      ],
      "steps": 30,
      "cfg": 6,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "1",
        0
      ],
      "positive": [
        "2",
        0
      ],
      "negative": [
        "3",
        0
      ],
      "latent_image": [
        "221",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "219": {
    "inputs": {
      "seed": "{seed1}"
    },
    "class_type": "Seed (rgthree)",
    "_meta": {
      "title": "Seed (rgthree)"
    }
  },
  "221": {
    "inputs": {
      "width": 512,
      "height": 760,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "빈 잠재 이미지"
    }
  },
  "229": {
    "inputs": {
      "model_name": "GroundingDINO_SwinT_OGC (694MB)"
    },
    "class_type": "GroundingDinoModelLoader (segment anything)",
    "_meta": {
      "title": "GroundingDinoModelLoader (segment anything)"
    }
  },
  "231": {
    "inputs": {
      "masks": [
        "246",
        1
      ]
    },
    "class_type": "Convert Masks to Images",
    "_meta": {
      "title": "Convert Masks to Images"
    }
  },
  "234": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "CLIP_VISION 로드"
    }
  },
  "235": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": [
        "1",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "238": {
    "inputs": {
      "left": 2,
      "top": 2,
      "right": 2,
      "bottom": 2,
      "mask": [
        "246",
        1
      ]
    },
    "class_type": "FeatherMask",
    "_meta": {
      "title": "마스크 가장자리 흐리게"
    }
  },
  "239": {
    "inputs": {
      "grow_mask_by": 6,
      "pixels": [
        "198",
        0
      ],
      "vae": [
        "1",
        2
      ],
      "mask": [
        "238",
        0
      ]
    },
    "class_type": "VAEEncodeForInpaint",
    "_meta": {
      "title": "VAE 인코드 (인페인팅용)"
    }
  },
  "243": {
    "inputs": {
      "model_name": "sam_vit_h (2.56GB)"
    },
    "class_type": "SAMModelLoader (segment anything)",
    "_meta": {
      "title": "SAMModelLoader (segment anything)"
    }
  },
  "246": {
    "inputs": {
      "prompt": [
        "153",
        0
      ],
      "threshold": 0.3,
      "sam_model": [
        "243",
        0
      ],
      "grounding_dino_model": [
        "229",
        0
      ],
      "image": [
        "198",
        0
      ]
    },
    "class_type": "GroundingDinoSAMSegment (segment anything)",
    "_meta": {
      "title": "GroundingDinoSAMSegment (segment anything)"
    }
  },
  "249": {
    "inputs": {
      "text": "(worst quality, low quality:1.3), blurry, bad anatomy, deformed, duplicate, disfigured, extra limbs, bad hands, bad clothing, poorly drawn clothes, out of frame, cropped\n",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP 텍스트 인코딩 (프롬프트)"
    }
  },
  "250": {
    "inputs": {
      "weight": 1,
      "weight_type": "strong style transfer",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "235",
        0
      ],
      "ipadapter": [
        "235",
        1
      ],
      "image": [
        "317",
        0
      ],
      "attn_mask": [
        "238",
        0
      ],
      "clip_vision": [
        "234",
        0
      ]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "251": {
    "inputs": {
      "seed": [
        "323",
        0
      ],
      "steps": 20,
      "cfg": 10,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "250",
        0
      ],
      "positive": [
        "314",
        0
      ],
      "negative": [
        "249",
        0
      ],
      "latent_image": [
        "239",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "252": {
    "inputs": {
      "samples": [
        "251",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE 디코드"
    }
  },
  "265": {
    "inputs": {
      "text": ")"
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "284": {
    "inputs": {
      "background": true,
      "hat": true,
      "hair": true,
      "glove": true,
      "sunglasses": true,
      "upper_clothes": true,
      "dress": true,
      "coat": true,
      "socks": true,
      "pants": true,
      "jumpsuits": true,
      "scarf": true,
      "skirt": true,
      "face": false,
      "left_arm": true,
      "right_arm": true,
      "left_leg": true,
      "right_leg": true,
      "left_shoe": true,
      "right_shoe": true,
      "image": [
        "139",
        0
      ]
    },
    "class_type": "Cozy Human Parser LIP",
    "_meta": {
      "title": "Cozy Human Parser LIP"
    }
  },
  "285": {
    "inputs": {
      "masks": [
        "284",
        0
      ]
    },
    "class_type": "Convert Masks to Images",
    "_meta": {
      "title": "Convert Masks to Images"
    }
  },
  "286": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": true,
      "destination": [
        "285",
        0
      ],
      "source": [
        "139",
        0
      ],
      "mask": [
        "284",
        0
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "마스크된 이미지 합성"
    }
  },
  "287": {
    "inputs": {
      "transparency": false,
      "model": "u2net",
      "post_processing": false,
      "only_mask": false,
      "alpha_matting": false,
      "alpha_matting_foreground_threshold": 240,
      "alpha_matting_background_threshold": 10,
      "alpha_matting_erode_size": 10,
      "background_color": "white",
      "images": [
        "286",
        0
      ]
    },
    "class_type": "Image Rembg (Remove Background)",
    "_meta": {
      "title": "Image Rembg (Remove Background)"
    }
  },
  "288": {
    "inputs": {
      "images": [
        "287",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "이미지 미리보기"
    }
  },
  "312": {
    "inputs": {
      "image": "{image1}"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "이미지 로드"
    }
  },
  "314": {
    "inputs": {
      "text": [
        "315",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP 텍스트 인코딩 (프롬프트)"
    }
  },
  "315": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "true",
      "text_a": [
        "15",
        0
      ],
      "text_b": [
        "19",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "317": {
    "inputs": {
      "transparency": true,
      "model": "u2net",
      "post_processing": false,
      "only_mask": false,
      "alpha_matting": false,
      "alpha_matting_foreground_threshold": 240,
      "alpha_matting_background_threshold": 10,
      "alpha_matting_erode_size": 10,
      "background_color": "none",
      "images": [
        "286",
        0
      ]
    },
    "class_type": "Image Rembg (Remove Background)",
    "_meta": {
      "title": "Image Rembg (Remove Background)"
    }
  },
  "318": {
    "inputs": {
      "lora_name": "ip-adapter-faceid-plusv2_sd15_lora.safetensors",
      "strength_model": 1,
      "model": [
        "322",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoRA 로드 (모델 전용)"
    }
  },
  "319": {
    "inputs": {
      "guide_size": 384,
      "guide_size_for": true,
      "max_size": 1024,
      "seed": 187270156334601,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 0.5,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 10,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": true,
      "noise_mask_feather": 0,
      "tiled_encode": false,
      "tiled_decode": false,
      "image": [
        "252",
        0
      ],
      "model": [
        "318",
        0
      ],
      "clip": [
        "1",
        1
      ],
      "vae": [
        "1",
        2
      ],
      "positive": [
        "2",
        0
      ],
      "negative": [
        "3",
        0
      ],
      "bbox_detector": [
        "321",
        0
      ],
      "sam_model_opt": [
        "320",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "얼굴 디테일러"
    }
  },
  "320": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "AUTO"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  },
  "321": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "322": {
    "inputs": {
      "weight": 1,
      "weight_faceidv2": 1,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "1",
        0
      ],
      "ipadapter": [
        "325",
        0
      ],
      "image": [
        "312",
        0
      ],
      "clip_vision": [
        "324",
        0
      ],
      "insightface": [
        "326",
        0
      ]
    },
    "class_type": "IPAdapterFaceID",
    "_meta": {
      "title": "IPAdapter FaceID"
    }
  },
  "323": {
    "inputs": {
      "seed": "{seed2}"
    },
    "class_type": "Seed (rgthree)",
    "_meta": {
      "title": "Seed (rgthree)"
    }
  },
  "324": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "CLIP_VISION 로드"
    }
  },
  "325": {
    "inputs": {
      "ipadapter_file": "ip-adapter-faceid-plusv2_sd15.bin"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "326": {
    "inputs": {
      "provider": "CPU",
      "model_name": "buffalo_l"
    },
    "class_type": "IPAdapterInsightFaceLoader",
    "_meta": {
      "title": "IPAdapter InsightFace Loader"
    }
  },
  "339": {
    "inputs": {
      "images": [
        "198",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "이미지 미리보기"
    }
  },
  "340": {
    "inputs": {
      "images": [
        "252",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "이미지 미리보기"
    }
  },
  "342": {
    "inputs": {
      "images": [
        "319",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "이미지 미리보기"
    }
  }
}